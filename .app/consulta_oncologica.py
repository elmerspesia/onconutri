import streamlit as st
from transformers import pipeline

@st.cache_resource
def load_chat_model():
    return pipeline("text2text-generation", model="google/flan-t5-base")

@st.cache_resource
def load_translator():
    return pipeline("translation", model="Helsinki-NLP/opus-mt-en-pt")

def show_form():
    st.title("ü©∫ Formul√°rio de Consulta Oncol√≥gica")

    idade = st.selectbox("Idade", ["<30", "30-45", "46-60", ">60"])
    genero = st.selectbox("G√™nero", ["Masculino", "Feminino", "Outro"])
    tabagismo = st.selectbox("√â fumante?", ["Nunca fumou", "Fumante ocasional", "Fumante regular", "Ex-fumante"])
    alcool = st.selectbox("Consumo de √°lcool", ["Nunca", "Social", "Frequente", "Abuso"])
    historico_familiar = st.selectbox("Hist√≥rico familiar de c√¢ncer?", ["Nenhum", "Sim - parentes de 1¬∫ grau", "Sim - parentes distantes"])
    dieta = st.selectbox("Tipo de dieta predominante", ["Rica em vegetais e fibras", "Mista com carnes processadas", "Industrializada", "Vegetariana"])
    atividade_fisica = st.selectbox("Frequ√™ncia de atividade f√≠sica", ["Sedent√°rio", "1-2x por semana", "3+ vezes/semana"])
    exposicao = st.selectbox("Exposi√ß√£o a toxinas (agrot√≥xicos, radia√ß√£o)", ["Nenhuma", "Moderada", "Alta"])
    estresse = st.selectbox("N√≠vel de estresse di√°rio", ["Baixo", "M√©dio", "Alto"])

    if st.button("üîç Processar Consulta"):
        with st.spinner("Processando avalia√ß√£o com IA..."):

            # Engenharia de Prompt com CAG + DAG + RAG
            contexto_medico = (
                "Voc√™ √© um assistente m√©dico especializado em oncologia preventiva. "
                "Analise o perfil abaixo de acordo com estudos da OMS, INCA, PubMed e NCCN."
            )

            dados_struct = f"""
            Idade: {idade}
            G√™nero: {genero}
            Tabagismo: {tabagismo}
            √Ålcool: {alcool}
            Hist√≥rico familiar: {historico_familiar}
            Dieta: {dieta}
            Atividade f√≠sica: {atividade_fisica}
            Exposi√ß√£o a toxinas: {exposicao}
            Estresse: {estresse}
            """

            prompt = (
                f"{contexto_medico}\n\n"
                f"Paciente:\n{dados_struct}\n\n"
                "Avalie em portugu√™s:\n"
                "- O tipo mais prov√°vel de c√¢ncer com base nesse perfil\n"
                "- Um score num√©rico de propens√£o ao c√¢ncer (de 0.00 a 1.00)\n"
                "- Recomenda√ß√µes detalhadas de h√°bitos que reduzam esse risco\n"
                "- Diagn√≥stico preventivo completo\n\n"
                "Responda apenas em portugu√™s, com linguagem m√©dica clara e objetiva."
            )

            try:
                modelo = load_chat_model()
                saida = modelo(prompt, max_new_tokens=512)[0]['generated_text']

                tradutor = load_translator()
                traducao = tradutor(saida, max_length=512)[0]['translation_text']

                # Score extra√≠do por regex ou heur√≠stica (ajust√°vel)
                import re
                score_match = re.search(r'([0-1]\.\d{1,2})', traducao)
                score = float(score_match.group(1)) if score_match else 0.0

                st.success("Consulta processada com sucesso.")
                st.subheader("üìÑ Resultado da Consulta Oncol√≥gica")
                st.markdown(f"**üìä Score de propens√£o ao c√¢ncer:** `{score:.2f}`")
                st.markdown(f"**ü©∫ Diagn√≥stico e Recomenda√ß√£o:**\n\n{traducao}")

            except Exception as e:
                st.error("‚ùå Erro ao processar a consulta.")
                st.exception(e)
