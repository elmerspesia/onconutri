import streamlit as st
from transformers import pipeline
import re

# Cacheia o carregamento do modelo de IA
@st.cache_resource
def load_chat_model():
    return pipeline("text2text-generation", model="google/flan-t5-base")

# Fun√ß√£o principal do formul√°rio de consulta m√©dica oncol√≥gica
def show_form():
    st.title("ü©∫ Formul√°rio de Consulta Oncol√≥gica")

    # Coleta de informa√ß√µes do paciente
    idade = st.selectbox("Idade", ["<30", "30-45", "46-60", ">60"])
    genero = st.selectbox("G√™nero", ["Masculino", "Feminino", "Outro"])
    tabagismo = st.selectbox("√â fumante?", ["Nunca fumou", "Fumante ocasional", "Fumante regular", "Ex-fumante"])
    alcool = st.selectbox("Consumo de √°lcool", ["Nunca", "Social", "Frequente", "Abuso"])
    historico_familiar = st.selectbox("Hist√≥rico familiar de c√¢ncer?", ["Nenhum", "Sim - parentes de 1¬∫ grau", "Sim - parentes distantes"])
    dieta = st.selectbox("Tipo de dieta predominante", ["Rica em vegetais e fibras", "Mista com carnes processadas", "Industrializada", "Vegetariana"])
    atividade_fisica = st.selectbox("Frequ√™ncia de atividade f√≠sica", ["Sedent√°rio", "1-2x por semana", "3+ vezes/semana"])
    exposicao = st.selectbox("Exposi√ß√£o a toxinas (agrot√≥xicos, radia√ß√£o)", ["Nenhuma", "Moderada", "Alta"])
    estresse = st.selectbox("N√≠vel de estresse di√°rio", ["Baixo", "M√©dio", "Alto"])

    # Bot√£o para processar a IA
    if st.button("üîç Processar Consulta"):
        with st.spinner("Processando avalia√ß√£o com IA..."):

            # Prompt em portugu√™s nativo com Engenharia de Prompt para CAG + RAG
            contexto = (
                "Voc√™ √© um m√©dico oncologista com conhecimento em guidelines da OMS, INCA, PubMed e literatura cient√≠fica. "
                "Analise o seguinte perfil de paciente e forne√ßa:\n"
                "- O(s) tipo(s) mais prov√°vel(eis) de c√¢ncer com base nos fatores de risco\n"
                "- Um score de propens√£o oncol√≥gica de 0.00 a 1.00\n"
                "- Recomenda√ß√µes preventivas baseadas em evid√™ncias\n"
                "- Diagn√≥stico e orienta√ß√£o cl√≠nica em linguagem acess√≠vel\n\n"
            )

            respostas = f"""
            Idade: {idade}
            G√™nero: {genero}
            Tabagismo: {tabagismo}
            √Ålcool: {alcool}
            Hist√≥rico familiar: {historico_familiar}
            Dieta: {dieta}
            Atividade f√≠sica: {atividade_fisica}
            Exposi√ß√£o a toxinas: {exposicao}
            Estresse: {estresse}
            """

            prompt = contexto + "Perfil do paciente:\n" + respostas

            try:
                modelo = load_chat_model()
                resultado = modelo(prompt, max_new_tokens=512)[0]['generated_text']

                # Tenta extrair o score do texto
                score_match = re.search(r'([0-1]\.\d{1,2})', resultado)
                score = float(score_match.group(1)) if score_match else 0.0

                # Exibi√ß√£o
                st.success("‚úÖ Consulta processada com sucesso.")
                st.subheader("üìù Resultado da Consulta Oncol√≥gica")
                st.markdown(f"**üìä Score de Propens√£o ao C√¢ncer:** `{score:.2f}`")
                st.markdown(f"**üìÑ Diagn√≥stico e Recomenda√ß√£o:**\n\n{resultado}")

            except Exception as e:
                st.error("‚ùå Erro ao processar a IA.")
                st.exception(e)
